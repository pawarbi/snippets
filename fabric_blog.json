{'publicationDate': '2024-09-25',
 'updates': [{'workload': 'Power BI Desktop',
   'fabricItem': 'Power BI Desktop',
   'feature': 'Dark Mode Theme',
   'description': 'Provides a dark mode theme option for personalized data visualization.',
   'tasks': ['Visualize data']},
  {'workload': 'Power BI',
   'fabricItem': 'Report',
   'feature': 'Copilot Chat Pane Enhancement',
   'description': 'Provides automatic text-based answers and summaries across all report pages by default.',
   'tasks': ['Analyze and train data', 'Visualize data']},
  {'workload': 'Power BI',
   'fabricItem': None,
   'feature': 'Metrics Hub',
   'description': 'A new metric layer in Fabric for defining, discovering, and reusing trusted metrics across an organization.',
   'tasks': ['Track data', 'Visualize data']},
  {'workload': 'Core',
   'fabricItem': 'Environment',
   'feature': 'Trusted workspace access and Managed private endpoints',
   'description': 'Extends the availability of Trusted workspace access and Managed private endpoints to all F capacities and Trial capacities, enhancing data access security and connectivity.',
   'tasks': ['Get data', 'Store data']},
  {'workload': 'Core',
   'fabricItem': None,
   'feature': 'Multitenant organization (MTO)',
   'description': 'Supports Entra Id Multitenant Organizations, enabling users from multiple tenants to access Fabric and leverage their existing licenses.',
   'tasks': ['Get data', 'Analyze and train data']},
  {'workload': 'Core',
   'fabricItem': None,
   'feature': 'Git integration',
   'description': 'Allows syncing Fabric workspaces with Git repositories for version control and seamless collaboration.',
   'tasks': ['Get data', 'Prepare data', 'Analyze and train data']},
  {'workload': 'Core',
   'fabricItem': 'Data pipeline',
   'feature': 'Deployment pipeline redesign',
   'description': 'A redesigned deployment pipeline for more efficient and user-friendly deployment processes.',
   'tasks': ['Develop data']},
  {'workload': 'Core',
   'fabricItem': None,
   'feature': 'Homepage improvements',
   'description': 'Enhanced workspace focus, optimized quick access section and a collapsible learn section for improved user experience.',
   'tasks': []},
  {'workload': 'OneLake',
   'fabricItem': 'Mirrored Azure Databricks Catalog',
   'feature': 'Access Databricks Unity Catalog tables from Fabric',
   'description': 'Allows accessing Databricks Unity Catalog tables directly from Fabric using shortcuts, keeping Fabric data items synced with changes in UC.',
   'tasks': ['Get data']},
  {'workload': 'OneLake',
   'fabricItem': None,
   'feature': 'Google Cloud Storage and S3 Compatible shortcuts',
   'description': 'Provides general availability for GCS and S3 Compatible shortcuts for easy data access in Fabric, supporting caching and On-Premises Gateway.',
   'tasks': ['Get data']},
  {'workload': 'OneLake',
   'fabricItem': None,
   'feature': 'REST APIs for OneLake shortcuts',
   'description': 'Provides generally available REST APIs for programmatic creation and management of OneLake shortcuts.',
   'tasks': ['Get data']},
  {'workload': 'OneLake',
   'fabricItem': None,
   'feature': 'OneLake SAS',
   'description': 'Supports short-lived, user-delegated OneLake SAS for secure and controlled access using User Delegation Key and OneLake SAS token.',
   'tasks': ['Get data']},
  {'workload': 'Data Warehouse',
   'fabricItem': 'Warehouse',
   'feature': 'Copilot for Data Warehouse',
   'description': 'An AI assistant that helps generate T-SQL queries, explain code, fix errors, and answer data warehousing questions.',
   'tasks': ['Analyze and train data']},
  {'workload': 'Data Warehouse',
   'fabricItem': None,
   'feature': 'Delta column mapping in the SQL analytics endpoint',
   'description': 'Supports Delta tables with column mapping, allowing spaces and special characters in column names.',
   'tasks': ['Prepare data']},
  {'workload': 'Data Warehouse',
   'fabricItem': None,
   'feature': 'Enabling SQL analytics endpoint on schema enabled Lakehouse’s',
   'description': 'Enables querying Delta tables in schemas through the SQL analytics endpoint.',
   'tasks': ['Analyze and train data']},
  {'workload': 'Data Warehouse',
   'fabricItem': None,
   'feature': 'New editor improvements',
   'description': 'Improved ribbon consistency, unified dev tools, enhanced data grid capabilities, and multitasking between dynamic tabs for efficient SQL development.',
   'tasks': ['Analyze and train data']},
  {'workload': 'Data Warehouse',
   'fabricItem': None,
   'feature': 'Database Migration Experience',
   'description': 'Provides a private preview for migrating SQL Server, Synapse dedicated SQL pools, and other warehouses to Fabric Data Warehouse.',
   'tasks': ['Store data']},
  {'workload': 'Data Warehouse',
   'fabricItem': 'Notebook',
   'feature': 'TSQL Notebook',
   'description': 'Enables developing Fabric warehouse and consuming data using notebooks with T-SQL query execution, visualization, and documentation capabilities.',
   'tasks': ['Analyze and train data']},
  {'workload': 'Data Warehouse',
   'fabricItem': None,
   'feature': 'Nested Common Table Expression',
   'description': 'Supports Nested Common Table Expression (NCTE) for simplifying complex queries and improving readability.',
   'tasks': ['Analyze and train data']},
  {'workload': 'Data Engineering',
   'fabricItem': 'Notebook',
   'feature': 'High Concurrency mode for Notebooks in Pipelines',
   'description': 'Allows sharing Spark sessions across multiple notebooks in a pipeline for optimized resource utilization and faster job start times.',
   'tasks': ['Develop data']},
  {'workload': 'Data Engineering',
   'fabricItem': None,
   'feature': 'Workspace Level Setting to Reserve Maximum Cores for Jobs',
   'description': 'Provides a workspace-level setting to reserve maximum cores for active Spark jobs, ensuring core availability for critical jobs.',
   'tasks': ['Develop data']},
  {'workload': 'Data Engineering',
   'fabricItem': None,
   'feature': 'Session Expiry Control in Workspace Settings for Notebook Interactive Runs',
   'description': 'Allows administrators to set maximum expiration time for notebook interactive sessions to prevent unnecessary capacity consumption.',
   'tasks': ['Develop data']},
  {'workload': 'Data Engineering',
   'fabricItem': None,
   'feature': 'Spark Connector for Fabric DW – New Features',
   'description': 'Adds support for custom queries, PySpark, and Fabric Runtime 1.3 in the Spark connector for Fabric DW.',
   'tasks': ['Analyze and train data']},
  {'workload': 'Data Engineering',
   'fabricItem': 'Notebook',
   'feature': 'T-SQL Notebook',
   'description': 'Provides a notebook experience for T-SQL developers to develop warehouses, execute queries, and visualize results.',
   'tasks': ['Analyze and train data']},
  {'workload': 'Data Engineering',
   'fabricItem': None,
   'feature': 'Fabric Spark Diagnostic Emitter',
   'description': 'Collects logs and metrics from Spark applications and sends them to Azure Event Hubs, Azure Storage, and Azure Log Analytics.',
   'tasks': ['Develop data']},
  {'workload': 'Data Engineering',
   'fabricItem': 'Environment',
   'feature': 'Environment Artifact integration with Synapse VS Code extension',
   'description': 'Integrates Fabric environments with the Synapse VS Code extension for managing environments from VS Code.',
   'tasks': ['Develop data']},
  {'workload': 'Data Engineering',
   'fabricItem': 'Notebook',
   'feature': 'Notebook debug within vscode.dev',
   'description': 'Enables debugging Fabric Notebooks within vscode.dev.',
   'tasks': ['Develop data']},
  {'workload': 'Data Engineering',
   'fabricItem': 'API for GraphQ',
   'feature': 'Adding Python support in Fabric User Data Functions',
   'description': 'Adds support for Python functions in Fabric User Data Functions, enabling the use of Python libraries.',
   'tasks': ['Develop data']},
  {'workload': 'Data Engineering',
   'fabricItem': None,
   'feature': 'Invoke Fabric User Data Functions in Notebook',
   'description': 'Allows invoking User Defined Functions (UDFs) in PySpark code directly from Fabric Notebooks or Spark jobs.',
   'tasks': ['Develop data']},
  {'workload': 'Data Engineering',
   'fabricItem': None,
   'feature': 'Functions Hub in Fabric User Data Functions',
   'description': 'Provides a central hub for viewing, accessing, and managing User Data Functions.',
   'tasks': ['Develop data']},
  {'workload': 'Data Engineering',
   'fabricItem': None,
   'feature': 'Support for spaces in Lakehouse Delta table names',
   'description': 'Supports spaces in Lakehouse Delta table names, improving usability.',
   'tasks': ['Prepare data']},
  {'workload': 'Data Engineering',
   'fabricItem': None,
   'feature': 'Fabric Runtime 1.3 GA',
   'description': 'Advances Fabric Runtime 1.3 to General Availability, including Delta Lake 3.2, Python and R updates, and query-specific optimizations.',
   'tasks': ['Develop data']},
  {'workload': 'Data Engineering',
   'fabricItem': None,
   'feature': 'Native Execution Engine on Runtime 1.3',
   'description': 'Provides a Native Execution Engine compatible with Fabric Runtime 1.3 GA, enhancing Spark job and query performance.',
   'tasks': ['Develop data']},
  {'workload': 'Data Engineering',
   'fabricItem': None,
   'feature': 'Acceleration tab and UI enablement for the Native Execution Engine',
   'description': 'Simplifies activating the Native Execution Engine through environment settings or the UI.',
   'tasks': ['Develop data']},
  {'workload': 'Data Engineering',
   'fabricItem': None,
   'feature': 'Fabric Spark Runtimes Release Notes',
   'description': 'Provides detailed release notes for each Apache Spark-based runtime.',
   'tasks': ['Develop data']},
  {'workload': 'Data Engineering',
   'fabricItem': 'API for GraphQ',
   'feature': 'Enable/Disable Functionality in API for GraphQL',
   'description': 'Allows granular control over API access by enabling or disabling specific queries and mutations.',
   'tasks': ['Develop data']},
  {'workload': 'Data Engineering',
   'fabricItem': None,
   'feature': 'Public REST API of Livy Endpoint',
   'description': 'Provides a public REST API for the Livy endpoint to submit and execute Spark code without Notebooks or Spark Job Definitions.',
   'tasks': ['Develop data']},
  {'workload': 'Data Science',
   'fabricItem': 'AI Skill',
   'feature': 'Share Feature for Fabric AI Skill',
   'description': 'Allows sharing AI Skills with others using various permission models and managing versions.',
   'tasks': ['Analyze and train data']},
  {'workload': 'Data Science',
   'fabricItem': None,
   'feature': 'Data Wrangler support for Spark DataFrames',
   'description': 'Extends Data Wrangler to support Spark DataFrames and PySpark code generation.',
   'tasks': ['Analyze and train data']},
  {'workload': 'Data Science',
   'fabricItem': None,
   'feature': 'Usability improvements for Data Wrangler',
   'description': 'Provides new launch points, improved performance, and a new "Views" prompt for enhanced usability.',
   'tasks': ['Analyze and train data']},
  {'workload': 'Data Science',
   'fabricItem': 'Notebook',
   'feature': 'File editor in Notebook',
   'description': 'Allows viewing and editing files directly within the notebook.',
   'tasks': ['Analyze and train data']},
  {'workload': 'Real-Time Intelligence',
   'fabricItem': 'Real-Time Dashboard',
   'feature': 'Creating a Real time Dashboard by Copilot',
   'description': 'Automates the creation of real-time dashboards using Copilot, generating insights and data profiles.',
   'tasks': ['Visualize data']},
  {'workload': 'Real-Time Intelligence',
   'fabricItem': 'Real-Time Dashboard',
   'feature': 'Adding a real-time dashboard to an org app',
   'description': 'Allows including real-time dashboards in org apps for easy distribution to large user cohorts.',
   'tasks': ['Visualize data']},
  {'workload': 'Real-Time Intelligence',
   'fabricItem': None,
   'feature': 'New Real-Time Hub User Experience',
   'description': 'Redesigned Real-Time Hub with a new left navigation, "My Streams" page, rebranded "Add source" buttons, and new Eventstream connectors.',
   'tasks': ['Get data', 'Track data', 'Visualize data']},
  {'workload': 'Real-Time Intelligence',
   'fabricItem': 'Eventstream',
   'feature': 'New Streaming Sources via Eventstream Connectors',
   'description': 'Adds new Eventstream connectors for Azure SQL MI DB (CDC), SQL Server on VM DB (CDC), Apache Kafka, and Amazon MSK Kafka.',
   'tasks': ['Get data']},
  {'workload': 'Real-Time Intelligence',
   'fabricItem': 'Eventstream',
   'feature': 'Eventhouse as a new Destination in Eventstream',
   'description': 'Introduces Eventhouse as a new destination for data streams, enabling real-time analytics using KQL.',
   'tasks': ['Store data', 'Analyze and train data']},
  {'workload': 'Real-Time Intelligence',
   'fabricItem': 'Eventstream',
   'feature': 'Eventstream’s Integration with Managed Private Endpoint',
   'description': 'Integrates Eventstream with Managed Private Endpoint for secure data transmission.',
   'tasks': ['Get data']},
  {'workload': 'Real-Time Intelligence',
   'fabricItem': 'KQL Queryset',
   'feature': 'New look and feel of KQL Database',
   'description': 'Provides a redesigned KQL DB experience with a cleaner interface, visually rich cards, enhanced database page, and improved table view.',
   'tasks': ['Analyze and train data']},
  {'workload': 'Real-Time Intelligence',
   'fabricItem': 'KQL Queryset',
   'feature': 'Set alerts on KQL Querysets with Data Activator triggers',
   'description': 'Allows setting Data Activator alerts directly on KQL queries in KQL querysets.',
   'tasks': ['Track data']},
  {'workload': 'Real-Time Intelligence',
   'fabricItem': 'Real-Time Dashboard',
   'feature': 'Data Exploration with Top values feature',
   'description': 'Adds a "Top Values" feature for easier data exploration in Real-Time Dashboards.',
   'tasks': ['Analyze and train data', 'Visualize data']},
  {'workload': 'Real-Time Intelligence',
   'fabricItem': 'Real-Time Dashboard',
   'feature': 'Real-Time Dashboard lower than ever refresh rate',
   'description': 'Supports continuous and 10-second refresh rates for Real-Time Dashboards.',
   'tasks': ['Visualize data']},
  {'workload': 'Real-Time Intelligence',
   'fabricItem': None,
   'feature': 'Multivariate anomaly detection',
   'description': 'Enables real-time multivariate anomaly detection using Eventhouse, Spark, and OneLake.',
   'tasks': ['Analyze and train data']},
  {'workload': 'Real-Time Intelligence',
   'fabricItem': None,
   'feature': 'Enhanced Time Series Analysis',
   'description': 'Improves time series analysis by enabling item selection from legend, search, invert, and navigation using mouse and keyboard.',
   'tasks': ['Analyze and train data', 'Visualize data']},
  {'workload': 'Real-Time Intelligence',
   'fabricItem': None,
   'feature': 'Real-Time Intelligence Copilot conversational mode',
   'description': 'Adds a conversational mode to Copilot for more intuitive data exploration.',
   'tasks': ['Analyze and train data']},
  {'workload': 'Real-Time Intelligence',
   'fabricItem': None,
   'feature': 'New Rule Creation Experience',
   'description': 'Provides a new rule creation experience in Data Activator for enhanced monitoring and action capabilities.',
   'tasks': ['Track data']},
  {'workload': 'Real-Time Intelligence',
   'fabricItem': None,
   'feature': 'Easier teammate alerts in Power BI',
   'description': 'Streamlines adding recipients to Data Activator alerts directly within Power BI.',
   'tasks': ['Track data']},
  {'workload': 'Data Factory',
   'fabricItem': 'Dataflow Gen2',
   'feature': 'Copilot in Dataflow Gen2',
   'description': 'Makes Copilot capabilities generally available in Dataflows Gen2 for AI-powered dataflow design.',
   'tasks': ['Prepare data']},
  {'workload': 'Data Factory',
   'fabricItem': 'Dataflow Gen2',
   'feature': 'Fast Copy in Dataflow Gen2',
   'description': 'Provides generally available Fast Copy feature for efficient large data ingestion.',
   'tasks': ['Prepare data']},
  {'workload': 'Data Factory',
   'fabricItem': 'Dataflow Gen2',
   'feature': 'Incremental refresh for Dataflow Gen2',
   'description': 'Adds incremental refresh for Dataflows Gen2 to optimize data ingestion and transformation.',
   'tasks': ['Prepare data']},
  {'workload': 'Data Factory',
   'fabricItem': 'Dataflow Gen2',
   'feature': 'Certified connector updates',
   'description': 'Provides updates to certified connectors, including new connectors and updated existing ones.',
   'tasks': ['Get data']},
  {'workload': 'Data Factory',
   'fabricItem': 'Data pipeline',
   'feature': 'Fabric Pipeline Integration in On-premises Data Gateway',
   'description': 'Provides general availability for on-premises connectivity for data pipelines using the on-premises Data Gateway.',
   'tasks': ['Get data']},
  {'workload': 'Data Factory',
   'fabricItem': 'Data pipeline',
   'feature': 'Invoke remote pipeline in Data pipeline',
   'description': 'Allows invoking pipelines from Azure Data Factory (ADF) or Synapse Analytics pipelines within Fabric pipelines.',
   'tasks': ['Develop data']},
  {'workload': 'Data Factory',
   'fabricItem': 'Data pipeline',
   'feature': 'Spark Job environment parameters',
   'description': 'Enables using session tags for reusing existing Spark sessions in Fabric Spark Notebook activity.',
   'tasks': ['Develop data']},
  {'workload': 'Data Factory',
   'fabricItem': 'Mirrored Azure SQL Database',
   'feature': 'Mirroring Azure SQL Database',
   'description': 'Extends support for mirrored tables within additional SQL DDL operations.',
   'tasks': ['Store data']},
  {'workload': 'Data Factory',
   'fabricItem': 'Azure Data Factory',
   'feature': 'New Azure Data Factory Item',
   'description': 'Allows connecting and managing existing Azure Data Factory factories from Fabric workspace.',
   'tasks': ['Develop data']},
  {'workload': 'Data Factory',
   'fabricItem': None,
   'feature': 'Copy Job',
   'description': 'Provides a new Copy Job feature for streamlined data ingestion with batch and incremental copy support.',
   'tasks': ['Prepare data']}]}
